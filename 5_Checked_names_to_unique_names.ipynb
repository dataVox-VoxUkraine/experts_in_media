{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get unique names from text: find checked names in similarity dicts and select unique representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from uk_stemmer import UkStemmer\n",
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_ru = stem.snowball.SnowballStemmer(\"russian\") \n",
    "stemmer_ukr = UkStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'language', 'all_ent_str', 'name_and_kw', 'kw_and_ent',\n",
       "       'names_and_kw_str', 'names_str', 'names_sets_str',\n",
       "       'one_name_per_set_str', 'string_names_sets_str', 'filt_kw_names_str',\n",
       "       'checked_with_conllu', 'checked_names_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_path = '../data/entities_may.csv'\n",
    "entities = pd.read_csv(entities_path, index_col=[0])\n",
    "entities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['filt_kw_names_list'] = entities.filt_kw_names_str.str.split('ยง')\n",
    "entities['checked_names_list'] = entities.checked_names_str.str.split('ยง')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_name_sets_to_list(sets_str):\n",
    "    if pd.notna(sets_str):\n",
    "        return [part.split('<+>') for part in sets_str.split('<@>')]\n",
    "    return None\n",
    "\n",
    "def get_names_by_num(num_sets, names):\n",
    "    if isinstance(num_sets, list):\n",
    "        res = []\n",
    "        for num_set in num_sets:\n",
    "            name_set = [names[int(i)] for i in num_set]\n",
    "            res.append(name_set)\n",
    "        return res\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['name_sets_lists'] = entities.string_names_sets_str.apply(split_name_sets_to_list)\n",
    "entities['one_name_per_set'] = entities.one_name_per_set_str.str.split('<@>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_names(names_list, stemmer):\n",
    "    if isinstance(names_list, list): \n",
    "        res=[]\n",
    "        for name in names_list:\n",
    "            stemmed_name = []\n",
    "            for word in name.split():\n",
    "                st = stemmer(word)\n",
    "                if word[0].isupper():\n",
    "                    st = st.capitalize()\n",
    "                stemmed_name.append(st)\n",
    "            res.append(' '.join(stemmed_name))\n",
    "        return res\n",
    "    return None\n",
    "\n",
    "def stem_name(name, stemmer):\n",
    "    stemmed_name = []\n",
    "    for word in name.split():\n",
    "        st = stemmer(word)\n",
    "        if word[0].isupper():\n",
    "            st = st.capitalize()\n",
    "        stemmed_name.append(st)\n",
    "    return ' '.join(stemmed_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_names_in_dicts(name_ent_list, name_forms, one_name_list, stemmer):\n",
    "    if isinstance(name_ent_list, list):\n",
    "        res = []\n",
    "        if len(name_ent_list)==1:\n",
    "            return [stem_name(name_ent_list[0], stemmer)]\n",
    "        \n",
    "        for name in name_ent_list:\n",
    "            try:\n",
    "                for i in range(len(name_forms)):\n",
    "                    if name in name_forms[i]:\n",
    "                        res.append(one_name_list[i])\n",
    "            except:\n",
    "                print(name_ent_list, name_forms, one_name_list)\n",
    "        return res\n",
    "    return None\n",
    "#         stemmed_name = stem_str(name, stemmer)\n",
    "\n",
    "\n",
    "def find_checked_names_in_dicts(name_ent_list, checked_name_ent_list, name_forms, one_name_list, stemmer):\n",
    "    if isinstance(checked_name_ent_list, list) and isinstance(name_ent_list, list):\n",
    "        res = []\n",
    "        if len(name_ent_list)==1 and name_ent_list[0] in checked_name_ent_list:\n",
    "            return [stem_name(name_ent_list[0], stemmer)]\n",
    "        \n",
    "        for name in name_ent_list:\n",
    "            try:\n",
    "                if name in checked_name_ent_list:\n",
    "                    for i in range(len(name_forms)):\n",
    "                        if name in name_forms[i]:\n",
    "                            res.append(one_name_list[i])\n",
    "            except:\n",
    "                print(name_ent_list, name_forms, one_name_list)\n",
    "                \n",
    "        if len(res) > 0:\n",
    "            return res\n",
    "    return None\n",
    "#         stemmed_name = stem_str(name, stemmer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['kw_names_norm_form'] = entities.apply(lambda row: \n",
    "                                                find_checked_names_in_dicts(row.filt_kw_names_list,\n",
    "                                                                            row.checked_names_list, \n",
    "                                                                      row.name_sets_lists, \n",
    "                                                                      row.one_name_per_set,\n",
    "                                                                      stemmer_ukr.stem_word) if row.language=='uk'\n",
    "                                                else find_checked_names_in_dicts(row.filt_kw_names_list,\n",
    "                                                                                 row.checked_names_list, \n",
    "                                                                      row.name_sets_lists, \n",
    "                                                                      row.one_name_per_set,\n",
    "                                                                      stemmer_ru.stem), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['kw_names_unique'] = entities['kw_names_norm_form'].apply(lambda x: \n",
    "                                                                   list(dict.fromkeys(x)) if isinstance(x, list)\n",
    "                                                                  else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['kw_names_unique_str'] = entities.kw_names_unique.str.join('ยง')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'language', 'all_ent_str', 'name_and_kw', 'kw_and_ent',\n",
       "       'names_and_kw_str', 'names_str', 'names_sets_str',\n",
       "       'one_name_per_set_str', 'string_names_sets_str', 'filt_kw_names_str',\n",
       "       'checked_with_conllu', 'checked_names_str', 'filt_kw_names_list',\n",
       "       'checked_names_list', 'name_sets_lists', 'one_name_per_set',\n",
       "       'kw_names_norm_form', 'kw_names_unique', 'kw_names_unique_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities[['link', 'language', 'all_ent_str', 'name_and_kw', 'kw_and_ent',\n",
    "       'names_and_kw_str', 'names_str', 'names_sets_str',\n",
    "       'one_name_per_set_str', 'string_names_sets_str', 'filt_kw_names_str',\n",
    "       'checked_with_conllu', 'checked_names_str', 'kw_names_unique_str']].to_csv(entities_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
